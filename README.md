### Decision_Tree_machine_learning

![image](https://github.com/Tejashripatil25/Decision_Tree_machine_learning/assets/124791646/ccec949c-af96-40b0-aa2e-31c9ab9be257)

A decision tree is a supervised learning algorithm that is used for classification and regression modeling. Regression is a method used for predictive modeling, so these trees are used to either classify data or predict what will come next. 

Decision trees look like flowcharts, starting at the root node with a specific question of data, that leads to branches that hold potential answers. The branches then lead to decision (internal) nodes, which ask more questions that lead to more outcomes. This goes on until the data reaches what’s called a terminal (or “leaf”) node and ends.

Decision trees are a popular machine learning algorithm that can be used for both regression and classification tasks. They are easy to understand, interpret, and implement, making them an ideal choice for beginners in the field of machine learning.

### Decision tree terminology

These terms come up frequently in machine learning and are helpful to know as you embark on your machine learning journey:

Root node: The topmost node of a decision tree that represents the entire message or decision

Decision (or internal) node: A node within a decision tree where the prior node branches into two or more variables

Leaf (or terminal) node: The leaf node is also called the external node or terminal node, which means it has no child—it’s the last node in the decision tree and furthest from the root node

Splitting: The process of dividing a node into two or more nodes. It’s the part at which the decision branches off into variables

Pruning: The opposite of splitting, the process of going through and reducing the tree to only the most important nodes or outcomes
